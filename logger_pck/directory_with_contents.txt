logger_pck
└── logger_pck
│   ├── package.json
│   ├── README.md
│   ├── script.js
    └── src
    │   ├── api.js
    │   ├── config.js
    │   ├── db.js
    │   ├── index.js
    │   ├── logger-util.js
    │   ├── logger.js
        ├── sync.js



File: package.json

{
  "name": "logger_pck",
  "version": "3.0.6",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "start": "node index.js"
  },
  "keywords": [
    "logging",
    "logger",
    "database",
    "fallback"
  ],
  "author": "Deepam Kumar",
  "license": "MIT",
  "description": "A logging package with database and local storage fallback",
  "dependencies": {
    "body-parser": "^1.20.3",
    "cors": "^2.8.5",
    "dotenv": "^16.4.5",
    "express": "^4.21.1",
    "find-free-port": "^2.0.0",
    "pg": "^8.13.1",
    "sequelize": "^6.37.5",
    "winston": "^3.16.0"
  }
}



File: README.md

# Logger PCK

A robust logging package with database integration and local storage fallback, allowing flexible logging for applications. This package is designed to log messages to a PostgreSQL database and automatically save logs locally if there’s a database failure, ensuring that no log data is lost.

## Table of Contents

- [Features](#features)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
  - [Basic Logging](#basic-logging)
  - [Logging Execution Time for Functions](#logging-execution-time-for-functions)
  - [Using with Express Routes](#using-with-express-routes)
- [Advanced Usage](#advanced-usage)
  - [Syncing Failed Logs to Database](#syncing-failed-logs-to-database)
  - [Accessing Logs via the API Server](#accessing-logs-via-the-api-server)
- [Error Handling and Troubleshooting](#error-handling-and-troubleshooting)
- [License](#license)

## Features

- **Database Logging**: Logs messages to a PostgreSQL database for centralized, persistent logging.
- **Local Fallback**: If the database is unreachable, logs are stored locally in JSON format and automatically retried for syncing at configurable intervals.
- **Multiple Log Types and Severity Levels**: Supports various log levels (`info`, `error`, `warning`, `success`) and severity levels (`low`, `medium`, `high`) for flexible categorization.
- **Execution Time Logging**: Provides a utility for logging the execution time of functions or routes, helping to monitor performance and identify bottlenecks.
- **API Endpoint and Metadata Tracking**: Logs include structured metadata, API endpoint tracking, and function name identification for better traceability.
- **API Server for Log Access**: Includes an optional Express-based API server for viewing, filtering, and managing logs.
- **Environment Configuration**: Fully configurable via environment variables, allowing easy setup and customization for different environments.

## Installation

Install the package using npm:

```bash
npm install logger_pck
```

## Configuration

### Step 1: Set Up PostgreSQL Database

Ensure you have PostgreSQL installed and a database created for logging. You can create a new database using:

```sql
CREATE DATABASE logger;
```

### Step 2: Configure Environment Variables

Create a `.env` file in your project root directory and set the following variables:

```plaintext
PORT=3000
DB_USER=postgres          # Use 'postgres' as the user to match the owner
DB_HOST=localhost
DB_NAME=logger            # Ensure DB_NAME is set to 'logger'
DB_PASSWORD=testbucket8600
DB_PORT=5432
DASHBOARD_URL=http://localhost:3000
APPLICATION_NAME=testapp
UNSYNCED_LOGS_PATH=./logs/unsynced_logs.json  # Specify path for unsynced logs
SYNC_INTERVAL=60000  # Sync interval in milliseconds (1 minute = 60000 ms)
```

## Usage

### Basic Logging

To log messages, import the `logMessage` function and call it with your message and metadata.

```javascript
const { logMessage } = require('logger_pck/src/utils');

logMessage('This is an informational message', 'info', { userId: 123 });
logMessage('An error occurred', 'error', { error: 'File not found' });
```

### Logging Execution Time for Functions

You can log the execution time of any function by wrapping it with `logWithExecutionTime`.

```javascript
const { logWithExecutionTime } = require('logger_pck/src/utils');

async function fetchData() {
    // Simulate a delay
    await new Promise(resolve => setTimeout(resolve, 500));
    return 'Data fetched successfully';
}

const loggedFetchData = logWithExecutionTime(fetchData, 'fetchData');
loggedFetchData();
```

This will log the start time, end time, and total execution time of `fetchData`.

### Using with Express Routes

To log the execution time of an Express route, use `logWithExecutionTime` to wrap the route handler:

```javascript
const express = require('express');
const { logWithExecutionTime } = require('logger_pck/src/utils');

const app = express();

app.get('/test', logWithExecutionTime(async (req, res) => {
    res.send('This is a test endpoint');
}, '/test'));

app.listen(3000, () => {
    console.log('Server is running on http://localhost:3000');
});
```

## Advanced Usage
You can use this comlte util also in your project
```javascript
// src/utils.js
const { log } = require('logger_pck/src/logger-util');

/**
 * Logs a custom message with metadata.
 * @param {String} message - The log message.
 * @param {String} logType - The type of log (e.g., 'info', 'error', 'success').
 * @param {String} apiEndpoint - The API endpoint or function associated with the log.
 * @param {String} severity - The severity level (e.g., 'low', 'medium', 'high').
 * @param {Object} metadata - Additional metadata for the log.
 */
function logMessage(message, logType = 'info', apiEndpoint = '', severity = 'low', metadata = {}) {
    log({
        logType,
        message,
        severity,
        apiEndpoint,
        metadata: {
            ...metadata,
            timestamp: new Date().toISOString(),
        },
    });
}

/**
 * Logs an error message.
 * @param {String} message - The error message.
 * @param {String} apiEndpoint - The API endpoint associated with the log.
 * @param {Object} metadata - Additional metadata for the log.
 */
function logError(message, apiEndpoint = '', metadata = {}) {
    logMessage(message, 'error', apiEndpoint, 'high', metadata);
}

/**
 * Logs a warning message.
 * @param {String} message - The warning message.
 * @param {String} apiEndpoint - The API endpoint associated with the log.
 * @param {Object} metadata - Additional metadata for the log.
 */
function logWarning(message, apiEndpoint = '', metadata = {}) {
    logMessage(message, 'warning', apiEndpoint, 'medium', metadata);
}

/**
 * Logs a success message.
 * @param {String} message - The success message.
 * @param {String} apiEndpoint - The API endpoint associated with the log.
 * @param {Object} metadata - Additional metadata for the log.
 */
function logSuccess(message, apiEndpoint = '', metadata = {}) {
    logMessage(message, 'success', apiEndpoint, 'low', metadata);
}

/**
 * Wraps a function to log its execution time and custom message.
 * @param {Function} func - The function to be wrapped.
 * @param {String} functionName - The name of the function being logged.
 * @param {String} severity - The severity level for execution log (default is 'low').
 * @param {String} apiEndpoint - The API endpoint or function associated with the log.
 * @returns {Function} - A new function that logs execution time and calls the original function.
 */
function logWithExecutionTime(func, functionName, severity = 'low', apiEndpoint = '') {
    return async function (...args) {
        const startTime = Date.now();
        let result;

        try {
            // Call the original function and store the result
            result = await func(...args);
        } catch (error) {
            // Log an error if the function throws an exception
            logError(`Error in ${functionName}: ${error.message}`, apiEndpoint, { functionName });
            throw error; // Re-throw the error after logging
        } finally {
            const endTime = Date.now();
            const executionTime = endTime - startTime;

            // Log the execution time and details
            logMessage(`${functionName} executed`, 'info', apiEndpoint, severity, {
                functionName,
                startTime,
                endTime,
                executionTime: `${executionTime}ms`,
            });
        }

        return result; // Return the original function's result
    };
}

module.exports = { logMessage, logError, logWarning, logSuccess, logWithExecutionTime };
```
Below is the example of how you can utilize util
```javascript
// index.js
const express = require('express');
const { logMessage, logError, logWarning, logSuccess, logWithExecutionTime } = require('./utils');
require('dotenv').config();

const app = express();
const PORT = process.env.PORT || 3000;

// Example function to demonstrate logging within a custom function
async function exampleFunction(param) {
    // Simulate some processing
    await new Promise(resolve => setTimeout(resolve, 100)); // 100ms delay
    return `Processed: ${param}`;
}

// Wrap `exampleFunction` with `logWithExecutionTime`
// Use severity 'medium' and specify the endpoint or function name
const loggedExampleFunction = logWithExecutionTime(exampleFunction, 'exampleFunction', 'medium', '/exampleFunction');

// Define a test endpoint to log execution time of `loggedExampleFunction`
app.get('/test', async (req, res) => {
    try {
        const result = await loggedExampleFunction('test param');
        logSuccess('GET /test endpoint accessed', '/test', { method: 'GET' });
        res.send(result);
    } catch (error) {
        logError('Error accessing /test endpoint', '/test', { method: 'GET' });
        res.status(500).send('Error occurred');
    }
});

// Start the server and log a success message
app.listen(PORT, () => {
    logSuccess(`Server started on port ${PORT}`, '/start', { port: PORT });
    console.log(`Backend server running on http://localhost:${PORT}`);
});
```

### Syncing Failed Logs to Database

If a log fails to be saved to the database, it will be stored locally in a JSON file (`logs/unsynced_logs.json`). The package automatically attempts to sync these failed logs to the database every 2 hours.

To configure the syncing interval, edit the `sync.js` file and adjust the `setInterval` function if needed.

### Accessing Logs via the API Server

The package includes an Express API server to view and filter logs. Start the server by calling:

```javascript
const { initializeLoggerService } = require('logger_pck/src/index');
initializeLoggerService();
```

#### API Endpoints

- **GET /logs**: Retrieves logs with optional query parameters.

  - **Query Parameters**:
    - `platform`: Filter by platform (e.g., app name).
    - `logType`: Filter by log type (e.g., info, error).
    - `date`: Filter by log date.

  - **Example**:
    ```bash
    curl http://localhost:4000/logs?platform=YourAppName&logType=info
    ```

## Error Handling and Troubleshooting

1. **Database Connection Issues**:
   - Ensure your PostgreSQL server is running and the credentials in `.env` are correct.
   - If connection issues persist, verify your network configuration or firewall settings.

2. **Syntax Errors in `unsynced_logs.json`**:
   - Malformed JSON in `unsynced_logs.json` can cause parsing errors during sync. Open the file, remove any incomplete or corrupted entries, and save it.

3. **Port Conflicts**:
   - If `EADDRINUSE` errors occur, change the port number for the API server in `.env` or by modifying `API_PORT` in `config.js`.

4. **Permission Issues**:
   - If you encounter file permission issues with `unsynced_logs.json`, ensure the application has write access to the directory.

## License

This package is licensed under the MIT License.


File: script.js

const fs = require('fs');
const path = require('path');

/**
 * Recursively reads a directory, generates its tree structure, and retrieves file contents.
 * @param {string} dirPath - The directory path to scan.
 * @param {string} prefix - The prefix for tree indentation.
 * @param {string[]} output - Array to store tree structure as a string.
 * @param {string[]} content - Array to store file content as strings.
 */
function processDirectory(dirPath, prefix = '', output = [], content = []) {
    const stats = fs.statSync(dirPath);

    if (stats.isFile()) {
        const fileName = path.basename(dirPath);
        output.push(`${prefix}├── ${fileName}`);
        
        // Read and store file content
        const fileData = fs.readFileSync(dirPath, 'utf8');
        content.push(`\n\nFile: ${fileName}\n\n${fileData}`);
    } else if (
        stats.isDirectory() && 
        !['.git', 'build','logs','node_modules'].includes(path.basename(dirPath)) // Exclude .git and build folders
    ) {
        const dirName = path.basename(dirPath);
        output.push(`${prefix}└── ${dirName}`);

        const children = fs.readdirSync(dirPath);

        // Recursively process children
        for (let i = 0; i < children.length; i++) {
            const childPath = path.join(dirPath, children[i]);
            const isLast = i === children.length - 1;
            processDirectory(
                childPath,
                `${prefix}${isLast ? '    ' : '│   '}`,
                output,
                content
            );
        }
    }
}

// The root folder to scan
const ROOT_FOLDER = path.resolve('./');

// Arrays to store tree structure and file contents
const treeOutput = [];
const fileContents = [];

// Generate tree structure and gather file contents
treeOutput.push(path.basename(ROOT_FOLDER));
processDirectory(ROOT_FOLDER, '', treeOutput, fileContents);

// Combine tree structure and file contents
const finalOutput = treeOutput.join('\n') + '\n\n' + fileContents.join('\n');

// Save the combined output to a file
const OUTPUT_FILE = path.join(ROOT_FOLDER, 'directory_with_contents.txt');
fs.writeFileSync(OUTPUT_FILE, finalOutput, 'utf8');

console.log(`Directory tree and file contents saved to ${OUTPUT_FILE}`);


File: api.js

// src/api.js
const express = require('express');
const { Log } = require('./db');
const Sequelize = require('sequelize');
const app = express();
const cors = require('cors');

app.use(cors({ origin: '*' }));

// Endpoint to retrieve logs (e.g., by platform, logType, date, apiEndpoint, sortBy, limit)
app.get('/logs', async (req, res) => {
    const {
        platform,
        logType,
        date,
        apiEndpoint,
        severity,
        userEmail,
        lastNMinutes,
        sortBy = 'createdAt',
        limit = 10
    } = req.query;
    // const { date } = req.body;

    // Building an array for the `AND` conditions
    const conditions = [];

    if (platform) conditions.push({ platform });
    if (logType) conditions.push({ logType });
    if (apiEndpoint) conditions.push({ apiEndpoint });
    if (severity) conditions.push({ severity });
    if (userEmail) conditions.push({ userEmail });

    // Handle `date` filter
    if (date) {
        conditions.push({ createdAt: { [Sequelize.Op.gte]: new Date(date) } });
    }

    // Handle `lastNMinutes` filter
    if (lastNMinutes) {
        const minutesAgo = new Date(Date.now() - parseInt(lastNMinutes) * 60000);
        conditions.push({ createdAt: { [Sequelize.Op.gte]: minutesAgo } });
    }

    const where = conditions.length ? { [Sequelize.Op.and]: conditions } : {};

    // Setting the order and limit options
    const options = {
        where,
        order: [[sortBy, 'DESC']], // Sort by createdAt or updatedAt, default to DESC
        limit: parseInt(limit),    // Convert limit to an integer
    };

    try {
        const logs = await Log.findAll(options);
        res.json(logs);
    } catch (error) {
        console.error('Error retrieving logs:', error); // Debugging log
        res.status(500).json({ error: 'Failed to retrieve logs', details: error.message });
    }
});

// create an API to get all unique API endpoints by platform or all if no platform specified
app.get('/apiendpoints', async (req, res) => {
    const { platform } = req.query;

    try {
        const where = platform ? { platform } : {}; // Filter by platform if provided
        const apiEndpoints = await Log.findAll({
            attributes: [[Sequelize.fn('DISTINCT', Sequelize.col('apiEndpoint')), 'apiEndpoint']],
            where,
        });

        // Add "All Endpoints" as the first entry
        const result = ['All Endpoints', ...apiEndpoints.map(endpoint => endpoint.get('apiEndpoint'))];

        res.json(result); // Return an array of unique API endpoints with "All Endpoints"
    } catch (error) {
        res.status(500).json({ error: 'Failed to retrieve API endpoints' });
    }
});


// Updated API to get all unique platforms with log counts and last log severity
app.get('/platforms', async (req, res) => {
    try {
        const platforms = await Log.findAll({
            attributes: [
                [Sequelize.col('platform'), 'DISTINCT'],
                [Sequelize.fn('COUNT', Sequelize.col('platform')), 'LOGCOUNT'],
                // Get the severity of the last log by ordering by createdAt and limiting to 1
                [Sequelize.literal(`(
                    SELECT "severity"
                    FROM "Logs" AS "LastLog"
                    WHERE "LastLog"."platform" = "Log"."platform"
                    ORDER BY "LastLog"."createdAt" DESC
                    LIMIT 1
                )`), 'lastSeverity']
            ],
            group: ['platform']
        });

        res.json(platforms.map(platform => ({
            DISTINCT: platform.get('DISTINCT'),
            LOGCOUNT: platform.get('LOGCOUNT'),
            lastSeverity: platform.get('lastSeverity')
        })));
    } catch (error) {
        res.status(500).json({ error: 'Failed to retrieve platforms with log counts and last log severity' });
    }
});

// create an API to get all the unique log types by platform, or all if no platform specified
// Updated API to get all unique log types by platform or all if no platform is provided
app.get('/logtypes', async (req, res) => {
    const { platform } = req.query;

    try {
        const where = platform ? { platform } : {}; // Filter by platform if provided
        const logTypes = await Log.findAll({
            attributes: [[Sequelize.fn('DISTINCT', Sequelize.col('logType')), 'logType']],
            where,
        });

        // Add "All Types" as the first entry
        const result = ['All Types', ...logTypes.map(type => type.get('logType'))];

        res.json(result); // Return an array of unique log types with "All Types"
    } catch (error) {
        res.status(500).json({ error: 'Failed to retrieve log types' });
    }
});


// create an api to get last n unique transactionIds
app.get('/transactionids', async (req, res) => {
    const { limit = 10 } = req.query;

    try {
        const transactionIds = await Log.findAll({
            attributes: [
                [Sequelize.literal('DISTINCT ON ("transactionId") "transactionId"'), 'transactionId']
            ],
            order: [['transactionId', 'ASC'], ['createdAt', 'DESC']],
            limit: parseInt(limit),
        });

        res.json(transactionIds.map(item => item.transactionId));
    } catch (error) {
        console.log("Error message:", error.message);
        res.status(500).json({ error: 'Failed to retrieve transaction IDs' });
    }
});



// create an api to get all the logs based on the trasaction id
app.get('/logs/:transactionId', async (req, res) => {
    const { transactionId } = req.params;

    try {
        const logs = await Log.findAll({ where: { transactionId } });
        res.json(logs);
    } catch (error) {
        res.status(500).json({ error: 'Failed to retrieve logs' });
    }
});

module.exports = app;



File: config.js

// src/config.js
require('dotenv').config();
const path = require('path');
const fs = require('fs');
const { env } = require('process');

// Get path for failed logs from environment or use default
const FAILED_LOGS_PATH = process.env.UNSYNCED_LOGS_PATH || path.join(__dirname, '../logs/unsynced_logs.json');

// Ensure the logs directory exists
if (!fs.existsSync(path.dirname(FAILED_LOGS_PATH))) {
    fs.mkdirSync(path.dirname(FAILED_LOGS_PATH), { recursive: true });
}

const config = {
    db: {
        user: process.env.DB_USER,
        host: process.env.DB_HOST,
        database: process.env.DB_NAME,
        password: process.env.DB_PASSWORD,
        port: process.env.DB_PORT,
    },
    enviornment: process.env.NODE_ENV || 'development',
    apiPort: (parseInt(process.env.PORT, 10) || 4000) + 1,
    dashboardUrl: process.env.DASHBOARD_URL,
    applicationName: process.env.APPLICATION_NAME,
    failedLogsPath: FAILED_LOGS_PATH,
    syncInterval: parseInt(process.env.SYNC_INTERVAL, 10) || 60000, // Default to 1 minute if not specified
};

module.exports = config;


File: db.js

// src/db.js
const { Sequelize, DataTypes } = require('sequelize');
const config = require('./config');

const sequelize = new Sequelize(config.db.database, config.db.user, config.db.password, {
    host: config.db.host,
    dialect: 'postgres',
    port: config.db.port,
    logging: false,
});

const Log = sequelize.define('Log', {
    environment: { type: DataTypes.STRING },
    platform: { type: DataTypes.STRING },
    logType: { type: DataTypes.STRING },
    severity: { type: DataTypes.STRING },
    message: { type: DataTypes.TEXT },
    apiEndpoint: { type: DataTypes.STRING },
    metadata: { type: DataTypes.JSONB },
    jsondata: { type: DataTypes.JSONB },
    transactionId: { type: DataTypes.STRING },
}, {
    timestamps: true, // Automatically adds createdAt and updatedAt fields
});

// Function to ensure the Log table exists
async function ensureLogTableExists() {
    try {
        await sequelize.authenticate();
        await sequelize.sync(); // Creates table if it doesn't exist
        console.log('Database connected and Log table ensured.');
    } catch (error) {
        console.error('Database connection or table creation failed:', error.message);
    }
}

module.exports = { sequelize, Log, ensureLogTableExists };



File: index.js

// src/index.js
const { sequelize } = require('./db');
const api = require('./api');
const config = require('./config');
const { syncFailedLogs } = require('./sync');

async function initializeLoggerService(customConfig = {}) {
    Object.assign(config, customConfig);

    await sequelize.authenticate();
    console.log(`Connected to database: ${config.db.database}`);

    // Start API server for log viewing
    api.listen(config.apiPort || 4000, () => {
        console.log(`Logger dashboard API server running on port ${config.apiPort}`);
    });

    // Sync any failed logs stored locally at startup
    syncFailedLogs();

    return { log: async (logData) => sequelize.models.Log.create(logData) };
}

module.exports = { initializeLoggerService };



File: logger-util.js

// src/logger-util.js
const { initializeLoggerService } = require('./index');
const { Log, ensureLogTableExists } = require('./db');
const config = require('./config');
const fs = require('fs');
// use uid  
const { v4: uuidv4 } = require('uuid');
let logger;
let isTableReady = false; // Flag to check if the log table is ready

// Initialize logger service and ensure the Log table exists
async function initializeLogger() {
    try {
        await ensureLogTableExists(); // Ensure the log table exists
        isTableReady = true; // Set flag to indicate the table is ready
        logger = await initializeLoggerService(config); // Initialize the logger service
        console.log('Logger service initialized successfully.');
    } catch (error) {
        console.error('Failed to initialize the logger service or ensure log table exists:', error.message);
    }
}

// Save failed logs locally
function saveFailedLogLocally(logData) {
    try {
        fs.appendFileSync(config.failedLogsPath, JSON.stringify(logData) + '\n');
        console.log('Log saved locally due to database error');
    } catch (error) {
        console.error('Failed to save log locally:', error);
    }
}

// Main log function
async function log({ platform, logType, message, severity, apiEndpoint, metadata = {}, jsondata = {}, transactionId }) {
    const logData = {
        environment: config.enviornment,
        platform : config.applicationName,
        logType,
        severity,
        apiEndpoint,
        message,
        metadata: { ...metadata, timestamp: new Date().toISOString() },
        jsondata: { ...jsondata, timestamp: new Date().toISOString() },
        transactionId : transactionId || uuidv4(),
    };

    if (logger && logger.log) {
        try {
            await logger.log(logData);
            console.log('Log saved to database');
        } catch (error) {
            console.error('Failed to log to database:', error.message);
            saveFailedLogLocally(logData);
        }
    } else {
        console.warn('Logger not initialized. Logging locally:', message);
        saveFailedLogLocally(logData);
    }
}

// Initialize logger on startup
initializeLogger();

module.exports = { log };


File: logger.js

const winston = require('winston');
const { Log } = require('./db');
const fs = require('fs');
const path = require('path');
const unsyncedLogsPath = path.join(__dirname, '../logs/unsynced_logs.json');

const logger = winston.createLogger({
    transports: [
        new winston.transports.Console(),
        new winston.transports.File({ filename: 'logs/app.log' }),
    ],
});

async function log({ platform, logType, message, metadata = {} }) {
    try {
        await Log.create({ platform, date: new Date(), logType, message, metadata });
        logger.info(`Logged to DB: ${message}`);
    } catch (error) {
        logger.error(`DB logging failed: ${error.message}`);
        fs.appendFileSync(unsyncedLogsPath, JSON.stringify({ platform, logType, message, metadata }) + '\n');
    }
}

module.exports = { log };



File: sync.js

// src/sync.js
const fs = require('fs');
const { Log } = require('./db');
const config = require('./config');

async function syncFailedLogs() {
    if (!fs.existsSync(config.failedLogsPath)) return;

    const logs = fs.readFileSync(config.failedLogsPath, 'utf8').split('\n').filter(line => line);
    const remainingLogs = [];

    for (const line of logs) {
        let logData;
        try {
            logData = JSON.parse(line); // Parse each line as JSON
        } catch (error) {
            console.error('Malformed log entry found and skipped:', line);
            continue; // Skip malformed entries
        }

        try {
            await Log.create(logData); // Attempt to save log to the database
            console.log('Synced log to database:', logData.message);
        } catch (error) {
            console.error('Failed to sync log:', error.message);
            remainingLogs.push(line); // Retain logs that couldn't be synced
        }
    }

    // Rewrite file with logs that still need syncing
    fs.writeFileSync(config.failedLogsPath, remainingLogs.join('\n'));
}

// Schedule syncing 
setInterval(syncFailedLogs, config.syncInterval);

module.exports = { syncFailedLogs };
